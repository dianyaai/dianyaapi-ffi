//
//  TranscribeView.swift
//  example (macOS)
//

import SwiftUI
import Combine

struct TranscribeView: View {
    @State private var isTranscribing = false
    @State private var transcriptions: [String] = []
    @State private var currentStatus: String = ""
    @State private var errorMessage: String = ""
    @State private var sessionInfo: SessionInfo?
    @State private var transcribeStream: TranscribeStream?
    @State private var partialResult: String = ""
    @StateObject private var audioRecorder = AudioRecorder()
    
    private let token = "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ1c2VyXzgzZTk5Y2YyIiwiZXhwIjoxNzY1MzU5Mjc4Ljk0ODk5fQ.JVL2o7u2IC-LhqFvSAmfE9oGVmnL7R4vfnxm_JA0V5k"
    
    var body: some View {
        VStack(spacing: 20) {
            Text("å®æ—¶è½¬å†™æµ‹è¯•ï¼ˆmacOSï¼‰")
                .font(.system(size: 28, weight: .bold))
                .padding(.top, 12)
            
            VStack(alignment: .leading, spacing: 8) {
                Text("è¾“å…¥éŸ³é¢‘")
                    .font(.headline)
                HStack {
                    VStack(alignment: .leading, spacing: 4) {
                        Text("ä½¿ç”¨ Mac éº¦å…‹é£è¿›è¡Œå®æ—¶è½¬å†™")
                            .font(.subheadline)
                        Text("åŸºäº AVAudioEngine + AVAudioConverter è½¬ 16kHz PCM16")
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                    Spacer()
                    Image(systemName: "mic.fill")
                        .foregroundColor(.blue)
                        .font(.title2)
                }
            }
            .padding()
            .frame(maxWidth: .infinity)
            .background(Color.blue.opacity(0.08))
            .cornerRadius(12)
            
            if !currentStatus.isEmpty {
                Text(currentStatus)
                    .font(.caption)
                    .foregroundColor(.secondary)
            }
            
            if !errorMessage.isEmpty {
                Text(errorMessage)
                    .font(.caption)
                    .foregroundColor(.red)
            }
            
            ScrollView {
                VStack(alignment: .leading, spacing: 8) {
                    if !partialResult.isEmpty {
                        Text("ğŸ”„ éƒ¨åˆ†ç»“æœï¼š\(partialResult)")
                            .padding()
                            .frame(maxWidth: .infinity, alignment: .leading)
                            .background(Color.orange.opacity(0.15))
                            .cornerRadius(8)
                    }
                    if transcriptions.isEmpty && partialResult.isEmpty {
                        Text("è½¬å†™ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...")
                            .foregroundColor(.secondary)
                            .padding()
                    } else {
                        ForEach(Array(transcriptions.enumerated()), id: \.offset) { index, text in
                            Text(text)
                                .padding()
                                .frame(maxWidth: .infinity, alignment: .leading)
                                .background(index % 2 == 0 ? Color.blue.opacity(0.1) : Color.green.opacity(0.1))
                                .cornerRadius(8)
                        }
                    }
                }
                .padding(.horizontal)
            }
            .frame(maxHeight: 360)
            
            HStack(spacing: 20) {
                Button(action: startTranscribing) {
                    HStack {
                        Image(systemName: "mic.fill")
                        Text("å¼€å§‹è½¬å†™")
                    }
                    .frame(maxWidth: .infinity)
                    .padding()
                    .background(isTranscribing ? Color.gray : Color.green)
                    .foregroundColor(.white)
                    .cornerRadius(10)
                }
                .disabled(isTranscribing)
                
                Button(action: { stopTranscribing() }) {
                    HStack {
                        Image(systemName: "stop.fill")
                        Text("åœæ­¢è½¬å†™")
                    }
                    .frame(maxWidth: .infinity)
                    .padding()
                    .background(isTranscribing ? Color.red : Color.gray)
                    .foregroundColor(.white)
                    .cornerRadius(10)
                }
                .disabled(!isTranscribing)
            }
            
            if !transcriptions.isEmpty {
                Button("æ¸…é™¤ç»“æœ") {
                    transcriptions.removeAll()
                }
                .buttonStyle(.bordered)
            }
            
            Spacer()
        }
        .padding(24)
        .onAppear {
            audioRecorder.ensureMicrophonePermissionStatus()
        }
        .onDisappear {
            stopTranscribing()
        }
    }
    
    private func startTranscribing() {
        guard !isTranscribing else { return }
        
        guard audioRecorder.hasPermission else {
            currentStatus = "â—ï¸ è¯·å…ˆæˆäºˆéº¦å…‹é£æƒé™"
            audioRecorder.ensureMicrophonePermissionStatus()
            return
        }
        
        isTranscribing = true
        errorMessage = ""
        transcriptions.removeAll()
        currentStatus = "æ­£åœ¨åˆ›å»ºä¼šè¯..."
        
        Task {
            do {
                let session = try await TranscribeStream.createSession(
                    token: token,
                    model: .speed
                )
                
                await MainActor.run {
                    sessionInfo = session
                    currentStatus = "âœ… ä¼šè¯åˆ›å»ºæˆåŠŸï¼Œå‡†å¤‡è¿æ¥ WebSocket..."
                }
                
                let stream = TranscribeStream(sessionInfo: session)
                try await stream.connect()
                
                await MainActor.run {
                    transcribeStream = stream
                    currentStatus = "âœ… WebSocket å·²è¿æ¥ï¼Œç­‰å¾…éŸ³é¢‘..."
                    
                    stream.startReceiving { message in
                        handleMessage(message)
                    }
                    
                    audioRecorder.onAudioData = { [weak stream] data in
                        guard let stream = stream else { return }
                        Task {
                            try? await stream.sendAudio(data)
                        }
                    }
                }
                
                do {
                    try audioRecorder.startRecording()
                    await MainActor.run {
                        currentStatus = "ğŸ¤ éº¦å…‹é£å·²å¯åŠ¨ï¼Œæ­£åœ¨è½¬å†™..."
                    }
                } catch {
                    throw error
                }
                
            } catch {
                await MainActor.run {
                    isTranscribing = false
                    errorMessage = "å¯åŠ¨å¤±è´¥: \(error.localizedDescription)"
                    currentStatus = ""
                }
            }
        }
    }
    
    private func stopTranscribing(dueToError: Bool = false) {
        guard isTranscribing else { return }
        isTranscribing = false
        
        if !dueToError {
            currentStatus = "æ­£åœ¨åœæ­¢è½¬å†™..."
        }
        
        Task {
            audioRecorder.stopRecording()
            audioRecorder.onAudioData = nil
            transcribeStream?.stop()
            transcribeStream?.disconnect()
            
            if let sessionInfo {
                do {
                    let closeResult = try await TranscribeStream.closeSession(
                        taskId: sessionInfo.taskId,
                        token: token,
                        timeout: 0
                    )
                    await MainActor.run {
                        if !dueToError {
                            if let duration = closeResult.duration {
                                currentStatus = "âœ… è½¬å†™å·²åœæ­¢ï¼Œç”¨æ—¶ \(duration) ç§’"
                            } else {
                                currentStatus = "âœ… è½¬å†™å·²åœæ­¢"
                            }
                        }
                    }
                } catch {
                    await MainActor.run {
                        if !dueToError {
                            currentStatus = "âš ï¸ å…³é—­ä¼šè¯å¤±è´¥: \(error.localizedDescription)"
                        }
                        errorMessage = "å…³é—­ä¼šè¯å¤±è´¥: \(error.localizedDescription)"
                    }
                }
            }
            
            await MainActor.run {
                transcribeStream = nil
                sessionInfo = nil
            }
        }
    }
    
    private func handleMessage(_ message: String) {
        guard let data = message.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let type = json["type"] as? String else {
            print("âš ï¸ [TranscribeView] æ— æ³•è§£ææ¶ˆæ¯: \(message)")
            return
        }
        
        switch type {
        case "stop":
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
                self.stopTranscribing()
            }
            
        case "error":
            if let errorData = json["data"] {
                let detail = "\(errorData)"
                errorMessage = "âŒ é”™è¯¯: \(detail)"
                stopTranscribing(dueToError: true)
            }
            
        case "asr_result":
            if let data = json["data"] as? [String: Any],
               let text = data["text"] as? String,
               !text.isEmpty {
                transcriptions.append("ğŸ“ \(text)")
                partialResult = ""
            }
            
        case "asr_result_partial":
            if let data = json["data"] as? [String: Any],
               let text = data["text"] as? String,
               !text.isEmpty {
                partialResult = text
            }
            
        default:
            print("â„¹ï¸ [TranscribeView] æœªçŸ¥æ¶ˆæ¯ç±»å‹: \(type)")
        }
    }
}

#Preview {
    TranscribeView()
}

