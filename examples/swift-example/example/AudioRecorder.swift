//
//  AudioRecorder.swift
//  example
//
//  Created by Jesse on 2025/11/19.
//  æ”¯æŒ iOS å’Œ macOS çš„ç»Ÿä¸€éŸ³é¢‘å½•åˆ¶å®ç°
//

import AVFoundation
import Combine

class AudioRecorder: ObservableObject {
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var audioFormat: AVAudioFormat?
    
    @Published var isRecording = false
    @Published var hasPermission = false
    
    private let targetSampleRate: Double = 16000  // ASR éœ€è¦ 16kHz
    private let channels: UInt32 = 1
    private let bufferSize: AVAudioFrameCount = 1024
    
    var onAudioData: ((Data) -> Void)?
    
    init() {
        requestMicrophonePermission()
    }
    
    func requestMicrophonePermission() {
        #if os(iOS)
        // iOS: ä½¿ç”¨ AVAudioSession
        let audioSession = AVAudioSession.sharedInstance()
        audioSession.requestRecordPermission { [weak self] granted in
            DispatchQueue.main.async {
                self?.hasPermission = granted
                if !granted {
                    print("âš ï¸ éº¦å…‹é£æƒé™æœªæˆäºˆ")
                }
            }
        }
        #elseif os(macOS)
        // macOS: ä½¿ç”¨ AVCaptureDevice
        AVCaptureDevice.requestAccess(for: .audio) { [weak self] granted in
            DispatchQueue.main.async {
                self?.hasPermission = granted
                if !granted {
                    print("âš ï¸ éº¦å…‹é£æƒé™æœªæˆäºˆ")
                }
            }
        }
        #endif
    }
    
    func ensureMicrophonePermissionStatus() {
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        switch audioSession.recordPermission {
        case .granted:
            DispatchQueue.main.async {
                self.hasPermission = true
            }
        case .undetermined:
            requestMicrophonePermission()
        case .denied:
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        @unknown default:
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        }
        #elseif os(macOS)
        let status = AVCaptureDevice.authorizationStatus(for: .audio)
        switch status {
        case .authorized:
            DispatchQueue.main.async {
                self.hasPermission = true
            }
        case .notDetermined:
            requestMicrophonePermission()
        case .denied, .restricted:
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        @unknown default:
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        }
        #endif
    }
    
    func startRecording() throws {
        print("ğŸ¤ [AudioRecorder] startRecording() å¼€å§‹")
        
        guard hasPermission else {
            print("âŒ [AudioRecorder] éº¦å…‹é£æƒé™æœªæˆäºˆ")
            throw AudioRecorderError.permissionDenied
        }
        
        guard !isRecording else {
            print("âš ï¸ [AudioRecorder] å·²ç»åœ¨å½•åˆ¶ä¸­")
            return
        }
        
        // åˆ›å»ºéŸ³é¢‘å¼•æ“
        let engine = AVAudioEngine()
        let input = engine.inputNode

        engine.prepare()

        // è·å–è¾“å…¥æ ¼å¼
        let inputFormat = input.outputFormat(forBus: 0)
        print("ğŸ“Š [AudioRecorder] è¾“å…¥éŸ³é¢‘æ ¼å¼: é‡‡æ ·ç‡=\(inputFormat.sampleRate), å£°é“æ•°=\(inputFormat.channelCount), æ ¼å¼=\(inputFormat.commonFormat)")
        
        // é…ç½®ç›®æ ‡éŸ³é¢‘æ ¼å¼ï¼š16kHz, å•å£°é“, PCM 16ä½ï¼ˆå‚è€ƒ ASRDemo2ï¼‰
        var outputAudioDescription = AudioStreamBasicDescription(
            mSampleRate: targetSampleRate,
            mFormatID: kAudioFormatLinearPCM,
            mFormatFlags: kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked,
            mBytesPerPacket: 2,  // 16-bit = 2 bytes
            mFramesPerPacket: 1,
            mBytesPerFrame: 2,  // 16-bit = 2 bytes
            mChannelsPerFrame: 1,
            mBitsPerChannel: 16,
            mReserved: 0
        )
        guard let targetFormat = AVAudioFormat(streamDescription: &outputAudioDescription) else {
            print("âŒ [AudioRecorder] æ— æ³•åˆ›å»ºç›®æ ‡éŸ³é¢‘æ ¼å¼ (16kHz, å•å£°é“, PCM Int16)")
            throw AudioRecorderError.formatError
        }
        
        print("ğŸ“Š [AudioRecorder] ç›®æ ‡éŸ³é¢‘æ ¼å¼é…ç½®:")
        print("   - é‡‡æ ·ç‡: \(targetFormat.sampleRate) Hz (16kHz)")
        print("   - å£°é“æ•°: \(targetFormat.channelCount) (å•å£°é“)")
        print("   - ä½æ·±åº¦: 16bit (PCM Int16)")
        print("   - æ ¼å¼: \(targetFormat.commonFormat)")
        
        // åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨
        let converter = AVAudioConverter(from: inputFormat, to: targetFormat)
        guard let converter = converter else {
            print("âŒ [AudioRecorder] æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨")
            throw AudioRecorderError.formatError
        }
        
        // æ˜ç¡®è®¾ç½®é‡‡æ ·ç‡è½¬æ¢å™¨è´¨é‡
        converter.sampleRateConverterQuality = AVAudioQuality.high.rawValue
        print("âœ… [AudioRecorder] éŸ³é¢‘è½¬æ¢å™¨åˆ›å»ºæˆåŠŸï¼Œé‡‡æ ·ç‡è½¬æ¢è´¨é‡: high")
        
        input.installTap(onBus: 0, bufferSize: bufferSize, format: inputFormat) { [weak self] buffer, time in
            guard let self = self, self.isRecording else { return }
            
            // è½¬æ¢æ ¼å¼ï¼ˆæ€»æ˜¯éœ€è¦è½¬æ¢ï¼Œå› ä¸ºé‡‡æ ·ç‡ä¸åŒï¼‰
            // è¾“å‡ºç¼“å†²åŒºå®¹é‡éœ€è¦æ ¹æ®é‡‡æ ·ç‡æ¯”ä¾‹è®¡ç®—
            let ratio = inputFormat.sampleRate > 0 ? targetFormat.sampleRate / inputFormat.sampleRate : 1.0
            let outputFrameCapacity = AVAudioFrameCount(ceil(Double(buffer.frameLength) * ratio))
            
            guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: outputFrameCapacity) else {
                print("âŒ [AudioRecorder] æ— æ³•åˆ›å»ºè½¬æ¢åçš„éŸ³é¢‘ç¼“å†²åŒº")
                return
            }
            
            var error: NSError?
            let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
                outStatus.pointee = .haveData
                return buffer
            }
            
            converter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)
            
            if let error = error {
                print("âŒ [AudioRecorder] éŸ³é¢‘è½¬æ¢é”™è¯¯: \(error)")
                return
            }
            
            // æå–PCMæ•°æ®
            guard convertedBuffer.format.commonFormat == .pcmFormatInt16,
                  let channelData = convertedBuffer.int16ChannelData else {
                print("âš ï¸ [AudioRecorder] è½¬æ¢åçš„ç¼“å†²åŒºæ ¼å¼ä¸æ­£ç¡®")
                return
            }
            
            let frameLength = Int(convertedBuffer.frameLength)
            let byteCount = frameLength * MemoryLayout<Int16>.size
            let data = Data(bytes: channelData[0], count: byteCount)
            // print("ğŸ¤ [AudioRecorder] è·å–åˆ°éº¦å…‹é£æ•°æ®ï¼Œé•¿åº¦: \(data.count) å­—èŠ‚ (\(frameLength) å¸§)")
            self.onAudioData?(data)
        }
        
        do {
            try engine.start()
            print("âœ… [AudioRecorder] éŸ³é¢‘å¼•æ“å¯åŠ¨æˆåŠŸ")
        } catch {
            print("âŒ [AudioRecorder] éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥: \(error)")
            print("âŒ [AudioRecorder] é”™è¯¯è¯¦æƒ…: \(error.localizedDescription)")
            if let nsError = error as NSError? {
                print("âŒ [AudioRecorder] é”™è¯¯ç : \(nsError.code), åŸŸ: \(nsError.domain)")
            }
            throw AudioRecorderError.engineError
        }
        
        self.audioEngine = engine
        self.inputNode = input
        self.audioFormat = targetFormat
        self.isRecording = true
        print("âœ… [AudioRecorder] å½•éŸ³å·²å¼€å§‹ï¼ŒisRecording = true")
    }
    
    func stopRecording() {
        print("ğŸ›‘ [AudioRecorder] stopRecording() å¼€å§‹")
        guard isRecording else {
            print("âš ï¸ [AudioRecorder] æœªåœ¨å½•åˆ¶ä¸­")
            return
        }
        
        inputNode?.removeTap(onBus: 0)
        audioEngine?.stop()
        audioEngine = nil
        inputNode = nil
        audioFormat = nil
        isRecording = false
        print("âœ… [AudioRecorder] å½•éŸ³å·²åœæ­¢")
    }
}

enum AudioRecorderError: LocalizedError {
    case permissionDenied
    case formatError
    case engineError
    
    var errorDescription: String? {
        switch self {
        case .permissionDenied:
            return "éº¦å…‹é£æƒé™æœªæˆäºˆ"
        case .formatError:
            return "éŸ³é¢‘æ ¼å¼é”™è¯¯"
        case .engineError:
            return "éŸ³é¢‘å¼•æ“é”™è¯¯"
        }
    }
}

